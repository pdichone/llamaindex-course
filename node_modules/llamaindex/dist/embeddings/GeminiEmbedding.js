import { BaseEmbedding } from "@llamaindex/core/embeddings";
import { GeminiSessionStore } from "../llm/gemini/base.js";
import { GEMINI_BACKENDS } from "../llm/gemini/types.js";
export var GEMINI_EMBEDDING_MODEL;
(function(GEMINI_EMBEDDING_MODEL) {
    GEMINI_EMBEDDING_MODEL["EMBEDDING_001"] = "embedding-001";
    GEMINI_EMBEDDING_MODEL["TEXT_EMBEDDING_004"] = "text-embedding-004";
})(GEMINI_EMBEDDING_MODEL || (GEMINI_EMBEDDING_MODEL = {}));
/**
 * GeminiEmbedding is an alias for Gemini that implements the BaseEmbedding interface.
 * Note: Vertex SDK currently does not support embeddings
 */ export class GeminiEmbedding extends BaseEmbedding {
    model;
    session;
    constructor(init){
        super();
        this.model = init?.model ?? "embedding-001";
        this.session = init?.session ?? GeminiSessionStore.get({
            backend: GEMINI_BACKENDS.GOOGLE
        });
    }
    async getEmbedding(prompt) {
        const client = this.session.getGenerativeModel({
            model: this.model
        });
        const result = await client.embedContent(prompt);
        return result.embedding.values;
    }
    getTextEmbedding(text) {
        return this.getEmbedding(text);
    }
}
